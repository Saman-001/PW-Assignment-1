{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558d618a-4d63-4287-9000-9ee07b564d9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd1ab8-09fe-4cfc-ba80-5f06fd028fe0",
   "metadata": {},
   "source": [
    "Web Scrapping - It is the process of extracting the desired information from the web. This information is further used for analysis,research purposes. We can use various languages to achieve the web scrapping and one of them is PYTHON.\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n",
    "\n",
    "Uses of webscrapping are as below :-\n",
    "1. It is used for Data extraction and analysis\n",
    "2. It is used for price monitoring and comparison.\n",
    "3. It is commonly used in sales and markting to generate leads.\n",
    "4. News websites, job boards and other platforms can use web scrapping to collect content from various resources.\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "\n",
    "Areas where web scrapping is used.\n",
    "\n",
    "1. E-Commerce and Retail.\n",
    "2. Social media monitoring.\n",
    "3. Job market research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365e789-e595-4079-91d5-6dcc7467508f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a23ed2-7589-446b-ab40-a37e15196ce9",
   "metadata": {},
   "source": [
    "Different methods for web scrapping are:-\n",
    "\n",
    "1. Manual copy-pasting -> In this humans manually copy and paste the data from the web.\n",
    "2. The pattern matching technique.\n",
    "3. HTML Parsing.\n",
    "4. DOM Parsing.\n",
    "5. Vertical Aggregation.\n",
    "6. Semantic Annotation Recognizing.\n",
    "7. Computer Vision page analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b212e43e-0015-44ef-86ca-2421e072c92e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3581127-8642-4f45-95d2-13656b453755",
   "metadata": {},
   "source": [
    " BeautifulSoup is the python library used for pulling out the data of HTML and XML files. It provides pyhonnic functio to search, iterate, modify the data of these files. It also helps to re-arrange the page source into a proper manner to some extent.\n",
    " \n",
    " Uses of BeautifulSoup are:-\n",
    " 1. HTML and XML parsing.\n",
    " 2. Easy Navigation and search.\n",
    " 3. Robust HTML Parsing.\n",
    " 4. Integration with Different Parsers.\n",
    " 5. Data Extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f49eaba-3bf3-4a39-9ebe-b4b3553daa16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7dd7ec-7f94-4bcf-bf42-80c15cc2268f",
   "metadata": {},
   "source": [
    "Flask is one of the API used to connect the python code with html files. It makes the communication very easy between the python and HTML files. \n",
    "\n",
    "In web scrapping project we have to scrap the data from the websites which are build on HTML and we have to do so by using  python language so, FLASK API helps us to build a bridge between them and makes easier to extract the data from the websites.\n",
    "Hence, this is the main reason to use Flask in our web scrapping project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdee85c-cdc1-4a9a-8512-fecb8df7c5f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Question 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32985cce-0947-40a2-ac5c-8120cd577e96",
   "metadata": {},
   "source": [
    "AWS services used in this project are as follows:-\n",
    "\n",
    "There are 2 services we used to deploy our project on AWS.\n",
    "\n",
    "1. Elastic BeanStalk -> This AWS service helps to provide the environment for the running of our project. It provides system,storage,RAM etc. to our project. This will run the project without utilising our system resources. In this we created a application and environment selecting the desired system requirements for our project and then making the environment live.\n",
    "\n",
    "\n",
    "\n",
    "2. Code PipeLine -> This AWS service helps us to connect our code from the github with AWS(Elastic BeanStalk). This service creates a bridge between the Github and AWS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cf8637-f0e4-4cee-b582-aeb109e2abee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
